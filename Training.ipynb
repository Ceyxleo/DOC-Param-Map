{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Open Rituals**\n",
    "\n",
    "Import needed package and define paths and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lli55\\AppData\\Local\\Temp\\ipykernel_5220\\1805901730.py:4: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "C:\\tools\\Anaconda3\\envs\\spyder\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\tools\\Anaconda3\\envs\\spyder\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "#%% open rituals ##############################################################\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from pandas import MultiIndex, Int64Index\n",
    "from optuna.samplers import TPESampler\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import spotpy\n",
    "import shap\n",
    "import math\n",
    "import os\n",
    "\n",
    "## define paths and functions ################################################\n",
    "### replace this main directory with your own\n",
    "Path_Main = r'C:\\Users\\lli55\\Desktop\\Lingbo Li PhD\\DOC project\\Model_with_SoilGrid'\n",
    "Path_Plot = os.path.join(Path_Main, 'plot')\n",
    "Path_Output = os.path.join(Path_Main, 'output')\n",
    "Path_Shape = os.path.join(Path_Main, 'shape')\n",
    "Path_Input = os.path.join(Path_Main, 'input')\n",
    "\n",
    "## matrics to use\n",
    "def kge_2009(preds, Dtrain):\n",
    "    y = Dtrain.get_label()\n",
    "    y_1 = [1e-6*i for i in y]\n",
    "    preds_1 = [1e-6*i for i in preds]\n",
    "    kge = spotpy.objectivefunctions.kge(y_1, preds_1)\n",
    "    if math.isnan(kge):\n",
    "        kge_1 = -9999\n",
    "    else:\n",
    "        kge_1 = kge\n",
    "    return 'kge', kge_1\n",
    "\n",
    "def nrmse(preds, Dtrain):\n",
    "    y = Dtrain.get_label()\n",
    "    y_1 = [1e-6*i for i in y]\n",
    "    preds_1 = [1e-6*i for i in preds]\n",
    "    nrmse = spotpy.objectivefunctions.rrmse(y_1, preds_1)\n",
    "    if math.isnan(nrmse):\n",
    "        nrmse_1 = -9999\n",
    "    else:\n",
    "        nrmse_1 = nrmse\n",
    "    return 'nrmse', nrmse_1\n",
    "\n",
    "\n",
    "def mase(preds, Dtrain): \n",
    "    y = Dtrain.get_label()\n",
    "    y_1 = np.array([1e-6*i for i in y])\n",
    "    preds_1 = np.array([1e-6*i for i in preds])\n",
    "    mae = np.mean(np.abs(y_1 - preds_1)) \n",
    "    gm = np.exp(np.mean(np.log(y_1))) \n",
    "    # rmse = spotpy.objectivefunctions.rmse(y_1, preds_1)\n",
    "    mase = mae / gm\n",
    "    return 'mase', mase\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.84368011e-05 1.28810757e-03]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(Path_Input, 'train_set.txt'), delimiter='\\t')\n",
    "data = data.dropna(subset = 'pr_soilgrid').reset_index(drop = True)\n",
    "print(np.quantile(data.pr_soilgrid, [0.05, 0.95]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.92744624e-05 8.42482632e-04]\n",
      "[7.42472628e-05 9.05163255e-04]\n",
      "1808 775\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(Path_Output, 'performance_12.csv'))\n",
    "data_train = data.dropna(subset = 'Y_train').reset_index(drop = True)\n",
    "data_test = data.dropna(subset = 'Y_test').reset_index(drop = True)\n",
    "print(np.quantile(data_train.Y_train, [0.1, 0.9]))\n",
    "print(np.quantile(data_test.Y_test, [0.1, 0.9]))\n",
    "print(len(data_train), len(data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model training, application, and analysis**\n",
    "\n",
    "- The feature selection process identified the following key predictors: ['TOT_A', 'TOT_NLCD01_90', 'TOT_CONTACT', 'TOT_B', 'TOT_I', 'TOT_BFI', 'TOT_E', 'TOT_CLAYAVE', 'TOT_HGB', 'TOT_NLCD01_42', 'TOT_NLCD01_95', 'TOT_CNPY11_BUFF100', 'TOT_HGBD'].\n",
    "\n",
    "- However, 'TOT_NLCD01_95' did not meet the representativeness criteria and will therefore be excluded from the final model training.\n",
    "\n",
    "- To assess the impact of this exclusion, we will compare the model's performance before (Model with 13 features) and after (Model with 12 features) removing this predictor.\n",
    "\n",
    "- Evaluate the model performance over training, testing and evaluation\n",
    "\n",
    "- Apply the final model to make a prediction over 2.6 million NHDPlus local catchments\n",
    "\n",
    "- Analysis the feature importance and the sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model with 13 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter tuning using optuna #########################################\n",
    "selected_feature = ['TOT_A', 'TOT_NLCD01_90', 'TOT_CONTACT', 'TOT_B', 'TOT_I', 'TOT_BFI', 'TOT_E', 'TOT_CLAYAVE', 'TOT_HGB', 'TOT_NLCD01_42', 'TOT_NLCD01_95', 'TOT_CNPY11_BUFF100', 'TOT_HGBD']\n",
    "\n",
    "## power transformation has already performed to predictors, pr is in its orginal value\n",
    "data = pd.read_csv(os.path.join(Path_Input, 'train_set.txt'), delimiter='\\t')\n",
    "data = data.dropna(subset = 'pr_soilgrid').reset_index(drop = True)\n",
    "Xx = data[selected_feature] \n",
    "## target variable has been transformed to 1e6 times its orginal value, as matrics mase favors large value\n",
    "Y = 1e6*data.pr_soilgrid\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xx, Y, test_size=0.3, random_state=1)\n",
    "Dtrain = xgb.DMatrix(X_train, label = Y_train, missing = np.nan)\n",
    "Dtest = xgb.DMatrix(X_test, label = Y_test, missing = np.nan)\n",
    "\n",
    "### define the objective funtion for optuna ###################################\n",
    "### those hyperparameter ranges could be adjusted, the following are chosen for model training using MASE.\n",
    "def objective_xgb_mase(trial):     \n",
    "    param = {\n",
    "        'booster':'gbtree',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-2, 1), # default value = 1\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 1e-1), # default value = 0\n",
    "        'gamma': trial.suggest_float('gamma', 1e-3, 1e-1), # default value = 0\n",
    "        'eta': trial.suggest_float('eta', 1e-1, 5e-1), # default value = 0.3\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1e-2, 1), # default value = 1\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 5e-1, 1), # default value = 1\n",
    "        'subsample': trial.suggest_float('subsample', 5e-1, 1), # default value = 1\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12), # default value = 6 \n",
    "        #'objective': 'reg:absoluteerror',\n",
    "        'disable_default_eval_metric':1\n",
    "    }\n",
    "    xgb_cv_results = xgb.cv(param,\n",
    "                    Dtrain,\n",
    "                    num_boost_round=800,\n",
    "                    seed=42,\n",
    "                    nfold=5,\n",
    "                    maximize = False, \n",
    "                    feval = mase,   \n",
    "                    callbacks=[xgb.callback.EvaluationMonitor(show_stdv=False),\n",
    "                               xgb.callback.EarlyStopping(rounds = 80,\n",
    "                                                          metric_name = 'mase',\n",
    "                                                          maximize = False)],   \n",
    "                    verbose_eval=False)     \n",
    "                      \n",
    "    mase_ = xgb_cv_results.iloc[-1]['test-mase-mean'] \n",
    "    trial.set_user_attr('n_estimators', len(xgb_cv_results))                      \n",
    "    return mase_\n",
    "\n",
    "## optuna learning process ####################################################\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# pay attention to maximize or minimize\n",
    "study = optuna.create_study(direction='minimize',sampler=TPESampler(seed=0)) \n",
    "study.optimize(objective_xgb_mase, n_trials=500, show_progress_bar=True)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "best_param = study.best_trial.params\n",
    "best_param['booster'] = 'gbtree'\n",
    "best_param['disable_default_eval_metric'] = 1\n",
    "n_estimators = study.best_trial.user_attrs['n_estimators']\n",
    "early_stop = int(n_estimators/10)\n",
    "## save the best model hyperparameter and n_estimator for later use\n",
    "print(best_param) \n",
    "print(n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model using best model hyperparameters ###########################\n",
    "optimised_xgb = xgb.train(\n",
    "                          best_param, \n",
    "                          Dtrain, \n",
    "                          num_boost_round=n_estimators, \n",
    "                          evals = [(Dtrain, 'eval_train'), (Dtest, 'eval_test')],\n",
    "                          feval=mase, # be consistent with your define function name\n",
    "                          maximize = False,  # Turn it to Ture if doing maximizing       \n",
    "                          callbacks=[xgb.callback.EvaluationMonitor(show_stdv=False),\n",
    "                                     xgb.callback.EarlyStopping(rounds = early_stop,\n",
    "                                                                metric_name = 'mase', # be consistent with your define function name\n",
    "                                                                maximize = False)],  # Turn it to Ture if doing maximizing \n",
    "                          verbose_eval=False\n",
    "                          ) \n",
    "\n",
    "## make prediction on training and testing data ##############################\n",
    "predicted_mean_train = optimised_xgb.predict(Dtrain, iteration_range=(0, optimised_xgb.best_iteration+1))\n",
    "predicted_mean_test  = optimised_xgb.predict(Dtest, iteration_range=(0, optimised_xgb.best_iteration+1))\n",
    "\n",
    "## evaluate the model performance on training and testing data\n",
    "print('trainning_kge:' + str(kge_2009(predicted_mean_train, Dtrain)))\n",
    "print('testing_kge:' + str(kge_2009(predicted_mean_test, Dtest)))\n",
    "print('trainning_nrmse:' + str(nrmse(predicted_mean_train, Dtrain)))\n",
    "print('testing_nrmse:' + str(nrmse(predicted_mean_test, Dtest)))\n",
    "print('trainning_MASE' + str(mase(predicted_mean_train, Dtrain)))\n",
    "print('testing_MASE:' + str(mase(predicted_mean_test, Dtest)))\n",
    "\n",
    "## evauate the model performance over evaluation catchments ###################\n",
    "## power transformation has already performed to predictors, pr is in its orginal value\n",
    "data_eval = pd.read_csv(os.path.join(Path_Input, 'eval_set.txt'), delimiter='\\t')\n",
    "data_eval = data_eval.dropna(subset = 'pr_soilgrid').reset_index(drop = True)\n",
    "X_val = data_eval[selected_feature]\n",
    "Y_val = 1e6*data_eval.pr_soilgrid\n",
    "Deval = xgb.DMatrix(X_val,  missing=np.nan)\n",
    "predicted_mean_eval  = optimised_xgb.predict(Deval, iteration_range=(0, optimised_xgb.best_iteration+1))\n",
    "\n",
    "## save those model predictions for later plotting\n",
    "performance = {\n",
    "    'Y_train': Y_train.values/1e6,\n",
    "    'Y_test': Y_test.values/1e6,  \n",
    "    'Y_val': Y_val.values/1e6,\n",
    "    'Predict_train_13':predicted_mean_train/1e6,\n",
    "    'Predict_test_13':predicted_mean_test/1e6,\n",
    "    'Predict_eval_13':predicted_mean_eval/1e6\n",
    "}\n",
    "\n",
    "df_performance = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in performance.items()]))\n",
    "df_performance.to_csv(os.path.join(Path_Output, 'performance_13.csv'), index = None)\n",
    "\n",
    "## Feature importance analysis using SHAP ####################################\n",
    "explainer = shap.TreeExplainer(optimised_xgb)\n",
    "shap_values = explainer.shap_values(Xx)\n",
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "## save feature importancce for later plotting\n",
    "importance = {\n",
    "    'predictors': selected_feature,\n",
    "    'SHAP_mean_13': shap_sum/1e6\n",
    "}\n",
    "df_importance = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in importance.items()]))\n",
    "df_importance.to_csv(os.path.join(Path_Output, 'importance_13.csv'), index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Final Model with 12 features**\n",
    "No obvious change of model performance after dropping the 'TOT_NLCD01_95', therefore 12 feature are selected for final optimal model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter tuning using optuna #########################################\n",
    "selected_feature = ['TOT_A', 'TOT_NLCD01_90', 'TOT_CONTACT', 'TOT_B', 'TOT_I', 'TOT_BFI', 'TOT_E', 'TOT_CLAYAVE', 'TOT_HGB', 'TOT_NLCD01_42', 'TOT_CNPY11_BUFF100', 'TOT_HGBD']\n",
    "\n",
    "## power transformation has already performed to predictors, pr is in its orginal value\n",
    "data = pd.read_csv(os.path.join(Path_Input, 'train_set.txt'), delimiter='\\t')\n",
    "data = data.dropna(subset = 'pr_soilgrid').reset_index(drop = True)\n",
    "Xx = data[selected_feature] \n",
    "## target variable has been transformed to 1e6 times its orginal value, as matrics mase favors large value\n",
    "Y = 1e6*data.pr_soilgrid\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xx, Y, test_size=0.3, random_state=1)\n",
    "Dtrain = xgb.DMatrix(X_train, label = Y_train, missing = np.nan)\n",
    "Dtest = xgb.DMatrix(X_test, label = Y_test, missing = np.nan)\n",
    "\n",
    "### define the objective funtion for optuna ###################################\n",
    "### those hyperparameter ranges could be adjusted, the following are chosen for model training using MASE.\n",
    "def objective_xgb_mase(trial):     \n",
    "    param = {\n",
    "        'booster':'gbtree',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-2, 1), # default value = 1\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 1e-1), # default value = 0\n",
    "        'gamma': trial.suggest_float('gamma', 1e-3, 1e-1), # default value = 0\n",
    "        'eta': trial.suggest_float('eta', 1e-1, 5e-1), # default value = 0.3\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1e-2, 1), # default value = 1\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 5e-1, 1), # default value = 1\n",
    "        'subsample': trial.suggest_float('subsample', 5e-1, 1), # default value = 1\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12), # default value = 6 \n",
    "        #'objective': 'reg:absoluteerror',\n",
    "        'disable_default_eval_metric':1\n",
    "    }\n",
    "    ## To monitor the progress, add 'xgb.callback.EvaluationMonitor(show_stdv=False)' into callbacks\n",
    "    xgb_cv_results = xgb.cv(param,\n",
    "                    Dtrain,\n",
    "                    num_boost_round=800,\n",
    "                    seed=42,\n",
    "                    nfold=5,\n",
    "                    maximize = False, \n",
    "                    feval = mase,   \n",
    "                    callbacks=[xgb.callback.EarlyStopping(rounds = 80,\n",
    "                                                          metric_name = 'mase',\n",
    "                                                          maximize = False)],   \n",
    "                    verbose_eval=False)     \n",
    "                      \n",
    "    mase_ = xgb_cv_results.iloc[-1]['test-mase-mean'] \n",
    "    trial.set_user_attr('n_estimators', len(xgb_cv_results))                      \n",
    "    return mase_\n",
    "\n",
    "## optuna learning process ####################################################\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# pay attention to maximize or minimize\n",
    "study = optuna.create_study(direction='minimize',sampler=TPESampler(seed=0)) \n",
    "study.optimize(objective_xgb_mase, n_trials=500, show_progress_bar=True)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "best_param = study.best_trial.params\n",
    "best_param['booster'] = 'gbtree'\n",
    "best_param['disable_default_eval_metric'] = 1\n",
    "n_estimators = study.best_trial.user_attrs['n_estimators']\n",
    "early_stop = int(n_estimators/10)\n",
    "## save the best model hyperparameter and n_estimator for later use\n",
    "print(best_param) \n",
    "print(n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model using best model hyperparameters ###########################\n",
    "selected_feature = ['TOT_A', 'TOT_NLCD01_90', 'TOT_CONTACT', 'TOT_B', 'TOT_I', 'TOT_BFI', 'TOT_E', 'TOT_CLAYAVE', 'TOT_HGB', 'TOT_NLCD01_42', 'TOT_CNPY11_BUFF100', 'TOT_HGBD']\n",
    "\n",
    "## best parameter returned from hyperparameter tuning\n",
    "best_param = {'lambda': 0.8497244598535406, 'alpha': 0.0219789569818175, 'gamma': 0.09045149625652132, 'eta': 0.11455856438869257, 'min_child_weight': 0.31227906516564546, 'colsample_bytree': 0.5004486262490111, 'subsample': 0.9729520009435804, 'max_depth': 8, 'booster': 'gbtree', 'disable_default_eval_metric': 1}\n",
    "n_estimators = 20\n",
    "early_stop = int(n_estimators/10)\n",
    "\n",
    "data = pd.read_csv(os.path.join(Path_Input, 'train_set.txt'), delimiter='\\t')\n",
    "data = data.dropna(subset = 'pr_soilgrid').reset_index(drop = True)\n",
    "Xx = data[selected_feature]\n",
    "Y = 1e6*data.pr_soilgrid\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xx, Y, test_size=0.3, random_state=1)\n",
    "Dtrain = xgb.DMatrix(X_train, label = Y_train, missing = np.nan)\n",
    "Dtest = xgb.DMatrix(X_test, label = Y_test, missing = np.nan)\n",
    "\n",
    "optimised_xgb = xgb.train(\n",
    "                          best_param, \n",
    "                          Dtrain, \n",
    "                          num_boost_round=n_estimators, \n",
    "                          evals = [(Dtrain, 'eval_train'), (Dtest, 'eval_test')],\n",
    "                          feval=mase, # be consistent with your define function name\n",
    "                          maximize = False,  # Turn it to Ture if doing maximizing       \n",
    "                          callbacks=[xgb.callback.EvaluationMonitor(show_stdv=False),\n",
    "                                     xgb.callback.EarlyStopping(rounds = early_stop,\n",
    "                                                                metric_name = 'mase', # be consistent with your define function name\n",
    "                                                                maximize = False)],  # Turn it to Ture if doing maximizing \n",
    "                          verbose_eval=False\n",
    "                          ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performances over training/testing/eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make prediction on training and testing data ##############################\n",
    "predicted_mean_train = optimised_xgb.predict(Dtrain, iteration_range=(0, optimised_xgb.best_iteration+1))\n",
    "predicted_mean_test  = optimised_xgb.predict(Dtest, iteration_range=(0, optimised_xgb.best_iteration+1))\n",
    "\n",
    "## evaluate the model performance on training and testing data\n",
    "print('trainning_kge:' + str(kge_2009(predicted_mean_train, Dtrain)))\n",
    "print('testing_kge:' + str(kge_2009(predicted_mean_test, Dtest)))\n",
    "print('trainning_nrmse:' + str(nrmse(predicted_mean_train, Dtrain)))\n",
    "print('testing_nrmse:' + str(nrmse(predicted_mean_test, Dtest)))\n",
    "print('trainning_MASE' + str(mase(predicted_mean_train, Dtrain)))\n",
    "print('testing_MASE:' + str(mase(predicted_mean_test, Dtest)))\n",
    "\n",
    "## evauate the model performance over evaluation catchments ###################\n",
    "## power transformation has already performed to predictors, pr is in its orginal value\n",
    "data_eval = pd.read_csv(os.path.join(Path_Input, 'eval_set.txt'), delimiter='\\t')\n",
    "data_eval = data_eval.dropna(subset = 'pr_soilgrid').reset_index(drop = True)\n",
    "X_val = data_eval[selected_feature]\n",
    "Y_val = 1e6*data_eval.pr_soilgrid\n",
    "Deval = xgb.DMatrix(X_val,  missing=np.nan)\n",
    "predicted_mean_eval  = optimised_xgb.predict(Deval, iteration_range=(0, optimised_xgb.best_iteration+1))\n",
    "\n",
    "## save those model predictions for later plotting\n",
    "performance = {\n",
    "    'Y_train': Y_train.values/1e6,\n",
    "    'Y_test': Y_test.values/1e6,  \n",
    "    'Y_val': Y_val.values/1e6,\n",
    "    'Predict_train_12':predicted_mean_train/1e6,\n",
    "    'Predict_test_12':predicted_mean_test/1e6,\n",
    "    'Predict_eval_12':predicted_mean_eval/1e6\n",
    "}\n",
    "\n",
    "df_performance = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in performance.items()]))\n",
    "df_performance.to_csv(os.path.join(Path_Output, 'performance_12.csv'), index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict over 2.6 million NHDPlus local catchments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_all = pd.read_csv(os.path.join(Path_Input, 'predict_set.txt'), delimiter= '\\t')\n",
    "X_predict = attr_all[selected_feature]\n",
    "Dtrain_predict = xgb.DMatrix(X_predict,  missing=np.nan)\n",
    "pr_conus  = optimised_xgb.predict(Dtrain_predict, iteration_range=(0, optimised_xgb.best_iteration+1))\n",
    "pr_conus_df = pd.DataFrame({'COMID': attr_all['COMID'],\n",
    "                      'pr': 1e-6*pr_conus})\n",
    "pr_conus_df.to_csv(os.path.join(Path_Output, 'pr_at_2_6m.txt'), sep = '\\t', index = None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature importance analysis using SHAP ####################################\n",
    "explainer = shap.TreeExplainer(optimised_xgb)\n",
    "shap_values = explainer.shap_values(Xx)\n",
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "## save feature importancce for later plotting\n",
    "importance = {\n",
    "    'predictors': selected_feature,\n",
    "    'SHAP_mean_12': shap_sum/1e6\n",
    "}\n",
    "df_importance = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in importance.items()]))\n",
    "df_importance.to_csv(os.path.join(Path_Output, 'importance_12.csv'), index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobol sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobol_problem = {\n",
    "    'num_vars': len(selected_feature),\n",
    "    'names': selected_feature,\n",
    "    'bounds': [[Xx[name].min(), Xx[name].max()] for name in selected_feature]\n",
    "}\n",
    "\n",
    "param_values = saltelli.sample(sobol_problem, 4096)\n",
    "Param = pd.DataFrame(param_values, columns = selected_feature)\n",
    "Dtrain_sobol = xgb.DMatrix(Param,  missing=np.nan)\n",
    "Sobol_Y = optimised_xgb.predict(Dtrain_sobol, iteration_range=(0, optimised_xgb.best_iteration+1))\n",
    "Si_coeff = sobol.analyze(sobol_problem, Sobol_Y)\n",
    "\n",
    "## save feature sobol sensitivity for later use\n",
    "sobol_sensitivity = {\n",
    "    'predictors': selected_feature,\n",
    "    'ST': Si_coeff['ST'],\n",
    "    'S1': Si_coeff['S1']\n",
    "}\n",
    "sobol_sensitivity_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in sobol_sensitivity.items()]))\n",
    "sobol_sensitivity_df.to_csv(os.path.join(Path_Output, 'sobol_sensitivity.csv'), index = None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f83720f3524ad70a07f8b9522dddf168ead5e164ced993ad70b21c480e663491"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('Hyriver': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
