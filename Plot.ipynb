{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Open Rituals**\n",
    "\n",
    "Import needed package and define paths and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% open rituals ##############################################################\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Transformer\n",
    "import matplotlib as mpl\n",
    "import geopandas as gpd\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spotpy\n",
    "import os\n",
    "\n",
    "### replace this main directory with your own\n",
    "Path_Main = r'C:\\Users\\lli55\\Desktop\\Lingbo Li PhD\\DOC project\\Model_with_SoilGrid'\n",
    "Path_Plot = os.path.join(Path_Main, 'plot')\n",
    "Path_Output = os.path.join(Path_Main, 'output')\n",
    "Path_Shape = os.path.join(Path_Main, 'shape')\n",
    "Path_Input = os.path.join(Path_Main, 'input')\n",
    "\n",
    "def get_density(x:np.ndarray, y:np.ndarray):\n",
    "    \"\"\"Get kernal density estimate for each (x, y) point.\"\"\"\n",
    "    values = np.vstack([x, y])\n",
    "    kernel = stats.gaussian_kde(values)\n",
    "    density = kernel(values)\n",
    "    return density\n",
    "\n",
    "def nrmse(sim, obs):\n",
    "    return spotpy.objectivefunctions.rrmse(obs, sim)\n",
    "\n",
    "def mase(preds, Dtrain): \n",
    "    y = Dtrain.get_label()\n",
    "    y_1 = np.array([1e-6*i for i in y])\n",
    "    preds_1 = np.array([1e-6*i for i in preds])\n",
    "    mae = np.mean(np.abs(y_1 - preds_1)) \n",
    "    gm = np.exp(np.mean(np.log(y_1))) \n",
    "    #rmse = spotpy.objectivefunctions.rmse(y_1, preds_1)\n",
    "    mase = mae / gm\n",
    "    return 'mase', mase\t\n",
    "\n",
    "def mase_plot(sim, obs): \n",
    "    y = np.array([i for i in obs])\n",
    "    pred = np.array([i for i in sim])\n",
    "    mae = np.mean(np.abs(y - pred)) \n",
    "    gm = np.exp(np.mean(np.log(y))) \n",
    "    return mae / gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **$P_r$ distribution map (Figure 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "Path_Main_Old = r'C:\\Users\\lli55\\Desktop\\Lingbo Li PhD\\DOC project'\n",
    "path_r = os.path.join(Path_Main_Old, 'USA_Rivers_and_Streams')\n",
    "\n",
    "# Load train and evaluation site locations\n",
    "train_loc = pd.read_csv(os.path.join(Path_Main_Old, '2595_train_sites.csv'), usecols=['lat', 'lon', 'comid'])\n",
    "eval_loc = pd.read_csv(os.path.join(Path_Main_Old, '3210_eval_sites.csv'), usecols=['lat', 'lon', 'comid'])\n",
    "\n",
    "# Load train and evaluation precipitation data\n",
    "train_pr = pd.read_csv(os.path.join(Path_Input, 'train_set.txt'), sep='\\t', usecols=['COMID', 'pr_soilgrid'])\n",
    "eval_pr = pd.read_csv(os.path.join(Path_Input, 'eval_set.txt'), sep='\\t', usecols=['COMID', 'pr_soilgrid'])\n",
    "\n",
    "# Merge train and evaluation sets with location data\n",
    "train_set = train_pr.merge(train_loc, left_on='COMID', right_on='comid').dropna().reset_index(drop=True)\n",
    "eval_set = eval_pr.merge(eval_loc, left_on='COMID', right_on='comid').dropna().reset_index(drop=True)\n",
    "\n",
    "# Function to cap outliers at the 5th and 95th percentiles\n",
    "def cap_outliers(df, column):\n",
    "    \"\"\"Cap values in the specified column to the 5th and 95th percentiles.\"\"\"\n",
    "    lower_bound = np.percentile(df[column], 5)\n",
    "    upper_bound = np.percentile(df[column], 95)\n",
    "    df[column] = np.clip(df[column], lower_bound, upper_bound)\n",
    "\n",
    "# Cap outliers for train and eval sets\n",
    "cap_outliers(train_set, 'pr_soilgrid')\n",
    "cap_outliers(eval_set, 'pr_soilgrid')\n",
    "\n",
    "# Load US boundary shapefile and extract the CONUS boundary\n",
    "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "conus_geo = world.loc[world['name'] == \"United States of America\", 'geometry'].iloc[0][0]\n",
    "conus = gpd.GeoDataFrame(geometry=[conus_geo], crs=world.crs)\n",
    "\n",
    "# Load and clip US rivers shapefile using CONUS boundary\n",
    "river = gpd.read_file(os.path.join(path_r, 'ne_10m_rivers_lake_centerlines.shp'))\n",
    "river_clipped = gpd.clip(river, conus)\n",
    "\n",
    "# Convert CRS of shapefiles to EPSG:5070 (Albers Equal Area)\n",
    "conus = conus.to_crs(\"EPSG:5070\")\n",
    "river_clipped = river_clipped.to_crs(\"EPSG:5070\")\n",
    "\n",
    "# Convert train and eval site locations to EPSG:5070\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:5070\", always_xy=True)\n",
    "\n",
    "train_set['lon_proj'], train_set['lat_proj'] = transformer.transform(train_set['lon'].values, train_set['lat'].values)\n",
    "eval_set['lon_proj'], eval_set['lat_proj'] = transformer.transform(eval_set['lon'].values, eval_set['lat'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global plot parameters\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Create figure and grid specification\n",
    "fig = plt.figure(figsize=(6, 7), constrained_layout=True)\n",
    "spec = fig.add_gridspec(2, 1)\n",
    "\n",
    "# Plot for train set\n",
    "ax0 = fig.add_subplot(spec[0, 0])\n",
    "ax0.set_title('a) $P_r$ of independent catchments', loc='left')\n",
    "im_1 = ax0.scatter(\n",
    "    train_set['lon_proj'], train_set['lat_proj'], \n",
    "    marker='o', \n",
    "    c=train_set['pr_soilgrid'], \n",
    "    s=5, \n",
    "    edgecolors='k', \n",
    "    linewidths=0.2, \n",
    "    cmap='rainbow'\n",
    ")\n",
    "river_clipped.plot(ax=ax0, color='grey', linewidth=0.5, label='riverline')\n",
    "conus.plot(ax=ax0, facecolor='none', edgecolor='k', linewidth=0.6, label='CONUS boundary')\n",
    "ax_cbar_1 = fig.colorbar(im_1, ax=ax0, shrink=0.6, pad=0.01, format='%.1e', extend='both')\n",
    "ax_cbar_1.set_label('$P_r$ ($m^3$ soil / $m^3$ water)')\n",
    "ax0.set_xlim([-2.5e6, 2.5e6])\n",
    "ax0.set_ylim([0.2e6, 3.3e6])\n",
    "ax0.axis('off')\n",
    "\n",
    "# Plot for evaluation set\n",
    "ax1 = fig.add_subplot(spec[1, 0])\n",
    "ax1.set_title('b) $P_r$ of evaluation catchments', loc='left')\n",
    "im_2 = ax1.scatter(\n",
    "    eval_set['lon_proj'], eval_set['lat_proj'], \n",
    "    marker='o', \n",
    "    c=eval_set['pr_soilgrid'], \n",
    "    s=5, \n",
    "    edgecolors='k', \n",
    "    linewidths=0.2,  \n",
    "    cmap='rainbow'\n",
    ")\n",
    "river_clipped.plot(ax=ax1, color='grey', linewidth=0.5, label='riverline')\n",
    "conus.plot(ax=ax1, facecolor='none', edgecolor='k', linewidth=0.6, label='CONUS boundary')\n",
    "ax_cbar_2 = fig.colorbar(im_2, ax=ax1, shrink=0.6, pad=0.01, format='%.1e', extend='both')\n",
    "ax_cbar_2.set_label('$P_r$ ($m^3$ soil / $m^3$ water)')\n",
    "ax1.set_xlim([-2.5e6, 2.5e6])\n",
    "ax1.set_ylim([0.2e6, 3.3e6])\n",
    "ax1.axis('off')\n",
    "\n",
    "# Save the figure\n",
    "output_path = os.path.join(Path_Plot, 'sites_distribution.png')\n",
    "fig.savefig(output_path, dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SHAP feature importance (Figure 3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_12 = pd.read_csv(os.path.join(Path_Output, 'importance_12.csv'))\n",
    "important_13 = pd.read_csv(os.path.join(Path_Output, 'importance_13.csv'))\n",
    "important = important_13.merge(important_12, on ='predictors', how = 'left')\n",
    "important_sorted = important.sort_values(by = 'SHAP_mean_12', ascending=False).reset_index(drop = True)\n",
    "# Rename columns for better readability\n",
    "predictors_mapping = {\n",
    "    'TOT_B': 'temp_related', \n",
    "    'TOT_CONTACT': 'CONTACT', \n",
    "    'TOT_A': 'hydro_related', \n",
    "    'TOT_I': 'elev_related', \n",
    "    'TOT_NLCD01_90': 'NLCD01_90', \n",
    "    'TOT_HGBD': 'HGBD', \n",
    "    'TOT_CNPY11_BUFF100': 'CNPY11_BUFF100', \n",
    "    'TOT_HGB': 'HGB', \n",
    "    'TOT_CLAYAVE': 'CLAYAVE', \n",
    "    'TOT_NLCD01_42': 'NLCD01_42', \n",
    "    'TOT_E': 'soil_texture_related', \n",
    "    'TOT_BFI': 'BFI', \n",
    "    'TOT_NLCD01_95': 'NLCD01_95'\n",
    "}\n",
    "\n",
    "# Replace values in the 'predictors' column\n",
    "important_sorted['predictors'] = important_sorted['predictors'].replace(predictors_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,5), constrained_layout=True)\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.rcParams['font.size'] = 10\n",
    "spec = fig.add_gridspec(1, 1)\n",
    "\n",
    "ax = fig.add_subplot(spec[0, 0])\n",
    "ax.grid(which=\"major\", axis='y', color='#DAD8D7', alpha=0.5, zorder=1)\n",
    "bar_width = 0.45\n",
    "# Define positions\n",
    "index = np.arange(len(important_sorted))\n",
    "\n",
    "# Plot bars for shap_15 and shap_12\n",
    "bars1 = ax.bar(index, important_sorted['SHAP_mean_13'], bar_width, label='13 predictors' ,zorder=2)\n",
    "bars2 = ax.bar(index + bar_width, important_sorted['SHAP_mean_12'], bar_width, label='12 predictors', color='orange' ,zorder=2)\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "ax.spines['bottom'].set_linewidth(1.1)\n",
    "ax.spines['left'].set_linewidth(1.1)\n",
    "ax.set_ylabel('Mean absolute SHAP value \\n($m^3 \\ soil/ m^3 \\ water$)')\n",
    "ax.set_xticks(index + bar_width/2)\n",
    "ax.set_xticklabels(important_sorted['predictors'], rotation=90, ha='center')\n",
    "ax.legend(loc=7, bbox_to_anchor=(0.98, 0.85), ncol=1, borderaxespad=0, frameon=True, fontsize=8)\n",
    "ax.set_ylim((0,6.5e-5))\n",
    "ax.set_xlim((-0.5,12.5))\n",
    "fig.savefig(os.path.join(Path_Plot,'SHAP_values_predictors.png'), dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Final model performance on $P_r$(Figure 4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load performance data\n",
    "performance_12 = pd.read_csv(os.path.join(Path_Output, 'performance_12.csv'))\n",
    "\n",
    "# Extract Y_train and Y_test after dropping NaNs\n",
    "Y_train = performance_12['Y_train'].dropna()\n",
    "Y_test = performance_12['Y_test'].dropna()\n",
    "predict_train_12 = performance_12['Predict_train_12'].dropna()\n",
    "predict_test_12 = performance_12['Predict_test_12'].dropna()\n",
    "\n",
    "# Create x-axis range\n",
    "x = np.arange(0, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the figure and layout\n",
    "fig = plt.figure(figsize=(8, 5), constrained_layout=True)\n",
    "spec = fig.add_gridspec(1, 2)\n",
    "\n",
    "# Plot for Training Data\n",
    "ax10 = fig.add_subplot(spec[0, 0])\n",
    "ax10.grid(which=\"both\", axis='x', color='#DAD8D7', alpha=0.5, zorder=1)\n",
    "ax10.grid(which=\"both\", axis='y', color='#DAD8D7', alpha=0.5, zorder=1)\n",
    "ax10.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "d10 = get_density(np.log10(Y_train), np.log10(predict_train_12))\n",
    "sca10 = ax10.scatter(Y_train, predict_train_12, s=10, edgecolor='k', linewidth=0, c=d10, cmap='RdYlBu', zorder=2, alpha=0.75)\n",
    "ax10.plot(x, x, color='k', linewidth=1)\n",
    "ax10.set_ylabel('Simulated $P_r$  ($m^3$ soil / $m^3$ water)')\n",
    "ax10.set_xlabel('Estimated $P_r$  ($m^3$ soil / $m^3$ water)')\n",
    "ax10.set_xscale('log')\n",
    "ax10.set_yscale('log')\n",
    "ax10.set_xlim((1e-5, 1e-2))\n",
    "ax10.set_ylim((1e-5, 1e-2))\n",
    "ax10.tick_params('both', length=10, width=1, which='major')\n",
    "ax10.tick_params('both', length=5, width=0.5, which='minor')\n",
    "ax10.set_title('a) Training', loc='left')\n",
    "\n",
    "ax10.text(1.2e-3, 1.5e-5, \n",
    "          f'MASE: {mase_plot(predict_train_12, Y_train):.2f}\\n' + \n",
    "          f'NRMSE: {nrmse(predict_train_12, Y_train):.2f}\\n' + \n",
    "          f'$R^2$: {np.corrcoef(Y_train, predict_train_12)[0, 1]:.2f}', \n",
    "          style='italic')\n",
    "\n",
    "cbar10 = plt.colorbar(sca10, location='bottom')\n",
    "cbar10.update_ticks()\n",
    "cbar10.set_label('Density of points')\n",
    "\n",
    "# Plot for Testing Data\n",
    "ax11 = fig.add_subplot(spec[0, 1])\n",
    "ax11.grid(which=\"both\", axis='x', color='#DAD8D7', alpha=0.5, zorder=1)\n",
    "ax11.grid(which=\"both\", axis='y', color='#DAD8D7', alpha=0.5, zorder=1)\n",
    "ax11.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "d11 = get_density(np.log10(Y_test), np.log10(predict_test_12))\n",
    "sca11 = ax11.scatter(Y_test, predict_test_12, s=10, edgecolor='k', linewidth=0, c=d11, cmap='RdYlBu', zorder=2)\n",
    "ax11.plot(x, x, color='k', linewidth=1)\n",
    "ax11.set_xlabel('Estimated $P_r$ ($m^3$ soil / $m^3$ water)')\n",
    "ax11.set_xscale('log')\n",
    "ax11.set_yscale('log')\n",
    "ax11.set_xlim((1e-5, 1e-2))\n",
    "ax11.set_ylim((1e-5, 1e-2))\n",
    "ax11.tick_params('x', length=8, width=1, which='major')\n",
    "ax11.tick_params('x', length=4, width=0.5, which='minor')\n",
    "ax11.tick_params('y', length=0, width=0, which='minor')\n",
    "ax11.set_yticks([])\n",
    "ax11.set_title('b) Testing', loc='left')\n",
    "\n",
    "ax11.text(1.2e-3, 1.5e-5, \n",
    "          f'MASE: {mase_plot(predict_test_12, Y_test):.2f}\\n' + \n",
    "          f'NRMSE: {nrmse(predict_test_12, Y_test):.2f}\\n' + \n",
    "          f'$R^2$: {np.corrcoef(Y_test, predict_test_12)[0, 1]:.2f}', \n",
    "          style='italic')\n",
    "\n",
    "cbar11 = plt.colorbar(sca11, location='bottom')\n",
    "cbar11.set_label('Density of points')\n",
    "\n",
    "# Set font size globally\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(os.path.join(Path_Plot, 'performance_pr.png'), dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Correlation heatmap (Figure 5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected predictors\n",
    "selected_feature = [\n",
    "    'pr_soilgrid', 'TOT_A', 'TOT_NLCD01_90', 'TOT_CONTACT', 'TOT_B', \n",
    "    'TOT_I', 'TOT_BFI', 'TOT_E', 'TOT_CLAYAVE', 'TOT_HGB', \n",
    "    'TOT_NLCD01_42', 'TOT_CNPY11_BUFF100', 'TOT_HGBD'\n",
    "]\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(os.path.join(Path_Input, 'train_set.txt'), delimiter='\\t')[selected_feature]\n",
    "\n",
    "# Rename columns for better readability\n",
    "data.rename(columns={\n",
    "    'pr_soilgrid': 'pr', \n",
    "    'TOT_A': 'hydro_related', \n",
    "    'TOT_NLCD01_90': 'NLCD01_90',\n",
    "    'TOT_CONTACT': 'CONTACT', \n",
    "    'TOT_B': 'temp_related', \n",
    "    'TOT_I': 'elev_related', \n",
    "    'TOT_BFI': 'BFI', \n",
    "    'TOT_E': 'soil_texture_related', \n",
    "    'TOT_CLAYAVE': 'CLAYAVE', \n",
    "    'TOT_HGB': 'HGB', \n",
    "    'TOT_NLCD01_42': 'NLCD01_42', \n",
    "    'TOT_CNPY11_BUFF100': 'CNPY11_BUFF100', \n",
    "    'TOT_HGBD': 'HGBD'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6.4))\n",
    "# Define the mask to set the values in the upper triangle to True\n",
    "mask = np.triu(np.ones_like(data.corr(), dtype=bool))\n",
    "\n",
    "# Set theme and color palette\n",
    "sns.set_theme(style=\"white\")\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Plot heatmap\n",
    "heatmap = sns.heatmap(\n",
    "    data.corr(), \n",
    "    mask=mask, \n",
    "    vmin=-0.8, \n",
    "    vmax=0.8, \n",
    "    annot=True, \n",
    "    cmap=cmap, \n",
    "    center=0, \n",
    "    square=True, \n",
    "    fmt='.2f', \n",
    "    cbar_kws={'label': 'Correlation coefficient'}, \n",
    "    annot_kws={\"size\": 10}\n",
    ")\n",
    "\n",
    "# Save heatmap plot\n",
    "plt.savefig(os.path.join(Path_Plot, 'Covariance_heatmap.png'), dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Spatial plots of Pr and DOC (Figure 6 & 9)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geospatial and predicted Pr over 2.6 million local catchment\n",
    "data = gpd.read_file(os.path.join(Path_Shape, 'SOC.gpkg'), driver='GPKG')\n",
    "pr_soilgrid = pd.read_csv(os.path.join(Path_Output, 'pr_at_2_6m.txt'), sep='\\t').rename(columns={'pr': 'pr_soilgrid'})\n",
    "Path_Output_old = r'C:\\Users\\lli55\\Desktop\\Lingbo Li PhD\\DOC project\\Data'\n",
    "pr_hwsd = pd.read_csv(os.path.join(Path_Output_old, 'pr_at_2_6m_mase.txt'), sep='\\t').rename(columns={'pr': 'pr_hwsd'})\n",
    "\n",
    "# Merge precipitation data with geospatial data\n",
    "data = data.merge(pr_hwsd, on='COMID', how='left')\n",
    "data = data.merge(pr_soilgrid, on='COMID', how='left')\n",
    "\n",
    "# Calculate DOC-related columns\n",
    "data['doc_hwsd'] = data['soc_hwsd'] * data['pr_hwsd']\n",
    "data['doc_soilgrid'] = data['soc_soilgrid'] * data['pr_soilgrid']\n",
    "\n",
    "# update the SOC.gpkg file\n",
    "data.to_file(os.path.join(Path_Shape, 'SOC.gpkg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Spatial Pr map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gpd.read_file(os.path.join(Path_Shape, 'SOC.gpkg'), driver='GPKG')\n",
    "data = data.to_crs(\"EPSG:5070\")\n",
    "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "conus_geo = world[world.name == \"United States of America\"].geometry.iloc[0][0]\n",
    "conus = gpd.GeoDataFrame(geometry=[conus_geo], crs=world.crs).to_crs(\"EPSG:5070\")\n",
    "quan_05, quan_95 = np.percentile(data['pr_soilgrid'], [5, 95])\n",
    "data['pr_soilgrid'].values[data['pr_soilgrid'].values > quan_95] = quan_95\n",
    "data['pr_soilgrid'].values[data['pr_soilgrid'].values < quan_05] = quan_05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(7, 5), constrained_layout=True)\n",
    "\n",
    "# Normalize color scale for 'pr_soilgrid'\n",
    "norm = colors.Normalize(vmin=quan_05, vmax=quan_95)\n",
    "cbar = plt.cm.ScalarMappable(norm=norm, cmap='rainbow')\n",
    "\n",
    "# Plot CONUS boundary and 'pr_soilgrid' data\n",
    "conus.plot(ax=ax, facecolor='none', edgecolor='k', linewidth=1)\n",
    "data.plot(ax=ax, column='pr_soilgrid', cmap='rainbow', linewidth=0.5, legend=False)\n",
    "\n",
    "# Add color bar\n",
    "ax_cbar = fig.colorbar(cbar, ax=ax, shrink=0.5, pad=0.01, extend='both', format='%0.0e')\n",
    "ax_cbar.set_label('$P_r$ ($m^3$ soil / $m^3$ water)')\n",
    "\n",
    "# Remove axis\n",
    "ax.axis('off')\n",
    "\n",
    "# Save the plot\n",
    "output_path = os.path.join(Path_Plot, 'conus_pr_map.png')\n",
    "fig.savefig(output_path, dpi=800, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Spatial DOC map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.dropna(subset = 'doc_soilgrid').copy()\n",
    "## Duo to missing values of SOC, only 2434427 catchment left for DOC calculation\n",
    "Y['doc_soilgrid'].values[Y['doc_soilgrid'].values > np.percentile(Y['doc_soilgrid'], 95)] = np.percentile(Y['doc_soilgrid'], 95)\n",
    "\n",
    "# Plot the map of DOC leaching fluxes\n",
    "fig, ax = plt.subplots(figsize=(7, 5), constrained_layout=True)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Normalize color scale for 'doc' values\n",
    "norm = colors.Normalize(vmin=0, vmax=12)\n",
    "cbar = plt.cm.ScalarMappable(norm=norm, cmap='rainbow')\n",
    "\n",
    "# Plot CONUS boundary and 'doc' column data\n",
    "conus.plot(ax=ax, facecolor='none', edgecolor='k', linewidth=1)\n",
    "Y.plot(ax=ax, column='doc_soilgrid', cmap='rainbow', linewidth=0.5, legend=False)\n",
    "\n",
    "# Add color bar\n",
    "ax_cbar = fig.colorbar(cbar, ax=ax, shrink=0.7, pad=0.01, extend='max')\n",
    "ax_cbar.set_label('$C_{DOC\\_runoff}$ ($mg/L$)')\n",
    "\n",
    "# Remove axis\n",
    "ax.axis('off')\n",
    "\n",
    "# Save the plot\n",
    "output_path_doc = os.path.join(Path_Plot, 'conus_doc_map.png')\n",
    "fig.savefig(output_path_doc, dpi=800, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DOC validation at evaluation catchments (Figure 7)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## those two data are in the same row order\n",
    "eval = pd.read_csv(os.path.join(Path_Output, 'eval_validation.txt'), sep = '\\t')\n",
    "## 2 catchments can does not have a valid derived DOC duo to missing in SOC data\n",
    "eval = eval.dropna(subset = 'derived_doc').reset_index(drop = True)\n",
    "obs = eval['ave_doc']\n",
    "sim = eval['derived_doc']\n",
    "d = get_density(np.log10(obs), np.log10(sim))\n",
    "x = np.arange(0, 200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5.5,5), constrained_layout=True)\n",
    "spec = fig.add_gridspec(1, 1)\n",
    "ax01 = fig.add_subplot(spec[0, 0])\n",
    "ax01.grid(which=\"both\", axis='x', color='#DAD8D7', alpha=0.5, zorder=1)\n",
    "ax01.grid(which=\"both\", axis='y', color='#DAD8D7', alpha=0.5, zorder=1)\n",
    "ax01.spines[['top','right']].set_visible(False)\n",
    "\n",
    "sca01 = ax01.scatter(obs, sim, s = 10, ec = 'k', linewidth = 0, c = d, cmap = 'RdYlBu', zorder=2, alpha = 0.75)\n",
    "ax01.plot(x,x, c = 'k', linewidth = 1)\n",
    "ax01.set_yscale('log')\n",
    "ax01.set_xscale('log')\n",
    "ax01.tick_params('both', length=8, width=1, which='major')\n",
    "ax01.tick_params('both', length=4, width=0.5, which='minor')\n",
    "ax01.set_xlim((2e-1,2e2))\n",
    "ax01.set_ylim((2e-1,2e2))\n",
    "ax01.set_ylabel('Derived $DOC$ concentration (mg/L)' )\n",
    "ax01.set_xlabel('Observed $DOC$ concentration (mg/L)')\n",
    "ax01.text(24, 0.3,\n",
    "          'MASE: ' + str(\"{:.2f}\".format(mase_plot(sim, obs))) + \n",
    "          '\\nNRMSE: ' + str(\"{:.2f}\".format(nrmse(sim, obs))) +\n",
    "          '\\n$R^2$: ' + str(\"{:.2f}\".format(np.corrcoef(obs, sim)[0,1])),\n",
    "          style='italic')\n",
    "# cbar = plt.colorbar(sca)\n",
    "# cbar.locator = MultipleLocator(base=0.5)\n",
    "# cbar.update_ticks()\n",
    "cbar01 = plt.colorbar(sca01)\n",
    "cbar01.set_label('Density of points')\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "fig.savefig(os.path.join(Path_Plot,'DOC_3208_eval.png'), dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model sensitivity plot (Figure 8)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature = ['TOT_A', 'TOT_NLCD01_90', 'TOT_CONTACT', 'TOT_B', 'TOT_I', 'TOT_BFI', 'TOT_E', 'TOT_CLAYAVE', 'TOT_HGB', 'TOT_NLCD01_42', 'TOT_CNPY11_BUFF100', 'TOT_HGBD']\n",
    "\n",
    "best_param = {'lambda': 0.8497244598535406, 'alpha': 0.0219789569818175, 'gamma': 0.09045149625652132, 'eta': 0.11455856438869257, 'min_child_weight': 0.31227906516564546, 'colsample_bytree': 0.5004486262490111, 'subsample': 0.9729520009435804, 'max_depth': 8, 'booster': 'gbtree', 'disable_default_eval_metric': 1}\n",
    "\n",
    "n_estimators = 20\n",
    "early_stop = int(n_estimators/10)\n",
    "data = pd.read_csv(os.path.join(Path_Input, 'train_set.txt'), delimiter='\\t')\n",
    "data = data.dropna(subset = 'pr_soilgrid').reset_index(drop = True)\n",
    "trains = []\n",
    "tests = []\n",
    "for item in selected_feature:\n",
    "    feature = [i for i in selected_feature if i != item]\n",
    "    Xx = data[feature]\n",
    "    Y = 1e6*data.pr_soilgrid\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(Xx, Y, test_size=0.3, random_state=1)\n",
    "    Dtrain = xgb.DMatrix(X_train, label = Y_train, missing = np.nan)\n",
    "    Dtest = xgb.DMatrix(X_test, label = Y_test, missing = np.nan)\n",
    "    ## CV to get the rigorois result of model preformance #####################\n",
    "    optimised_xgb = xgb.train(\n",
    "                              best_param, \n",
    "                              Dtrain, \n",
    "                              num_boost_round=n_estimators, \n",
    "                              evals = [(Dtrain, 'eval_train'), (Dtest, 'eval_test')],\n",
    "                              feval=mase, # be consistent with your define function name\n",
    "                              maximize = False,  # Turn it to Ture if doing maximizing       \n",
    "                              callbacks=[xgb.callback.EvaluationMonitor(show_stdv=False),\n",
    "                                         xgb.callback.EarlyStopping(rounds = early_stop,\n",
    "                                                                    metric_name = 'mase',\n",
    "                                                                    maximize = False)],\n",
    "                              verbose_eval=False\n",
    "                              ) \n",
    "    predicted_mean_train = optimised_xgb.predict(Dtrain, iteration_range=(0, optimised_xgb.best_iteration+1))\n",
    "    predicted_mean_test  = optimised_xgb.predict(Dtest, iteration_range=(0, optimised_xgb.best_iteration+1))\n",
    "    trains.append(mase_plot(predicted_mean_train/1e6, Y_train/1e6))\n",
    "    tests.append(mase_plot(predicted_mean_test/1e6, Y_test/1e6))\n",
    "\n",
    "objective = ('hydro_related', 'NLCD01_90', 'CONTACT', 'temp_related', 'elev_related', 'BFI', 'soil_texture_related', 'CLAYAVE', 'HGB', 'NLCD01_42', 'CNPY11_BUFF100', 'HGBD')\n",
    "y_pos = np.arange(len(objective))\n",
    "plot_data = pd.DataFrame({'label': y_pos,\n",
    "                          'train': trains,\n",
    "                          'test': tests})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 0.420420964803733\n",
    "below_average = plot_data[plot_data['train']<= 0.95*std]\n",
    "nc = plot_data[(plot_data['train']> 0.95*std) & (plot_data['train']< 1.05*std)]\n",
    "above_average = plot_data[plot_data['train']>= 1.05*std]\n",
    "colors_high = [\"#d7191c\", \"#d7191c\"] # Extreme colours of the high scale\n",
    "colors_nochange = ['#bababa', '#bababa']\n",
    "colors_low = [\"#2c7bb6\",\"#2c7bb6\"] # Extreme colours of the low scale\n",
    "\n",
    "cmap_low = mpl.colors.LinearSegmentedColormap.from_list(\"low_map\", colors_low, N=256)\n",
    "cmap_nochange = mpl.colors.LinearSegmentedColormap.from_list(\"low_map\", colors_nochange, N=256)\n",
    "cmap_high = mpl.colors.LinearSegmentedColormap.from_list(\"high_map\", colors_high, N=256)\n",
    "\n",
    "norm_low = mpl.colors.Normalize(below_average['train'].min(), 0.95*std) # linearly normalizes data into the [0.0, 1.0] interval\n",
    "norm_nochange = mpl.colors.Normalize(0.95*std, 1.05*std)\n",
    "norm_high = mpl.colors.Normalize(1.05*std, above_average['train'].max())\n",
    "\n",
    "fig = plt.figure(figsize=(6,6), constrained_layout=True)\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.rcParams['font.size'] = 10\n",
    "spec = fig.add_gridspec(2, 1)\n",
    "\n",
    "ax0 = fig.add_subplot(spec[0, 0])\n",
    "ax0.grid(which=\"major\", axis='y', color='#DAD8D7', alpha=0.5, zorder=1)\n",
    "\n",
    "bar1 = ax0.bar(below_average['label'], below_average['train'], color=cmap_low(norm_low(below_average['train'])), width=0.8, label='Increase$> 5\\%$', zorder=2)\n",
    "barnc = ax0.bar(nc['label'], nc['train'], color=cmap_nochange(norm_nochange(nc['train'])), width=0.8, label='No significant change', zorder=2)\n",
    "bar2 = ax0.bar(above_average['label'], above_average['train'], color=cmap_high(norm_high(above_average['train'])), width=0.8, label='Decrease$< 5\\%$', zorder=2)\n",
    "ax0.bar_label(bar1, labels=[f'{e:,.2f}' for e in below_average['train']], padding=3, color='black', fontsize=8, zorder = 4) \n",
    "ax0.bar_label(barnc, labels=[f'{e:,.2f}' for e in nc['train']], padding=3, color='black', fontsize=8, zorder = 4) \n",
    "ax0.bar_label(bar2, labels=[f'{e:,.2f}' for e in above_average['train']], padding=3, color='black', fontsize=8, zorder = 4) \n",
    "ax0.hlines(y = std , xmin=-1, xmax=12, linewidth=2, linestyle = '--', color = 'grey', label = 'All Feature' ,zorder = 3)\n",
    "\n",
    "ax0.set_ylabel('MASE')\n",
    "ax0.set_ylim((0.2, 0.6))\n",
    "ax0.set_xlim((-0.5,11.5))\n",
    "ax0.set_xticks([])\n",
    "ax0.set_title('a)Training', loc = 'left')\n",
    "ax0.spines[['top','right']].set_visible(False)\n",
    "ax0.spines['left'].set_linewidth(1.1)\n",
    "ax0.spines['bottom'].set_linewidth(1.1)\n",
    "ax0.tick_params(axis='x', which='both', length = 4, bottom=True, top=False, labelbottom=True)\n",
    "ax0.tick_params(axis='y', which='both', length = 4, left=True, right=False, labelleft=True)\n",
    "ax0.legend(loc=7, bbox_to_anchor=(0.98, 0.85), ncol=2, borderaxespad=0, frameon=True, fontsize=8)\n",
    "\n",
    "\n",
    "std_1 = 0.768564600388366\n",
    "below_average_1 = plot_data[plot_data['test']<=0.95*std_1]\n",
    "nc_1 = plot_data[(plot_data['test']>0.95*std_1) & (plot_data['test']<1.05*std_1)]\n",
    "above_average_1 = plot_data[plot_data['test']>=1.05*std_1]\n",
    "norm_low_1 = mpl.colors.Normalize(below_average_1['test'].min(), 0.95*std_1) # linearly normalizes data into the [0.0, 1.0] \n",
    "norm_nc_1 = mpl.colors.Normalize(0.95*std_1, 1.05*std_1)\n",
    "norm_high_1 = mpl.colors.Normalize(1.05*std_1, above_average_1['test'].max())\n",
    "\n",
    "\n",
    "ax1 = fig.add_subplot(spec[1, 0])\n",
    "ax1.grid(which=\"major\", axis='y', color='#DAD8D7', alpha=0.5, zorder=1)\n",
    "bar3 = ax1.bar(below_average_1['label'], below_average_1['test'], color=cmap_low(norm_low_1(below_average_1['test'])), width=0.8, zorder=2)\n",
    "barnc_1 = ax1.bar(nc_1['label'], nc_1['test'], color=cmap_nochange(norm_nc_1(nc_1['test'])), width=0.8, zorder=2)\n",
    "bar4 = ax1.bar(above_average_1['label'], above_average_1['test'], color=cmap_high(norm_high_1(above_average_1['test'])), width=0.8, zorder=2)\n",
    "ax1.bar_label(bar3, labels=[f'{e:,.2f}' for e in below_average_1['test']], padding=3, color='black', fontsize=8, zorder = 4) \n",
    "ax1.bar_label(barnc_1, labels=[f'{e:,.2f}' for e in nc_1['test']], padding=3, color='black', fontsize=8, zorder = 4) \n",
    "ax1.bar_label(bar4, labels=[f'{e:,.2f}' for e in above_average_1['test']], padding=3, color='black', fontsize=8, zorder = 4) \n",
    "ax1.hlines(y = std_1 , xmin=-1, xmax=12, linewidth=2, linestyle = '--', color = 'grey', label = 'All Feature' ,zorder = 3)\n",
    "\n",
    "ax1.set_xticks(y_pos)\n",
    "ax1.set_xticklabels(objective, rotation=90)\n",
    "ax1.set_ylabel('MASE')\n",
    "ax1.set_ylim((0.6,1))\n",
    "ax1.set_xlim((-0.5,11.5))\n",
    "ax1.set_title('b)Testing ', loc = 'left')\n",
    "ax1.spines[['top','right']].set_visible(False)\n",
    "ax1.spines['left'].set_linewidth(1.1)\n",
    "ax1.spines['bottom'].set_linewidth(1.1)\n",
    "ax1.tick_params(axis='x', which='major', length = 4, bottom=True, top=False, labelbottom=True)\n",
    "ax1.tick_params(axis='y', which='major', length = 4, left=True, right=False, labelleft=True)\n",
    "fig.savefig(os.path.join(Path_Plot,'model_sensitivity.png'), dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "STD_TRAIN = 0.420420964803733\n",
    "STD_TEST = 0.768564600388366\n",
    "COLOR_HIGH = [\"#d7191c\", \"#d7191c\"]\n",
    "COLOR_NOCHANGE = ['#bababa', '#bababa']\n",
    "COLOR_LOW = [\"#2c7bb6\", \"#2c7bb6\"]\n",
    "\n",
    "# Create color maps\n",
    "cmap_low = mpl.colors.LinearSegmentedColormap.from_list(\"low_map\", COLOR_LOW, N=256)\n",
    "cmap_nochange = mpl.colors.LinearSegmentedColormap.from_list(\"nochange_map\", COLOR_NOCHANGE, N=256)\n",
    "cmap_high = mpl.colors.LinearSegmentedColormap.from_list(\"high_map\", COLOR_HIGH, N=256)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6), constrained_layout=True)\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.rcParams['font.size'] = 10\n",
    "spec = fig.add_gridspec(2, 1)\n",
    "\n",
    "# Plot training data\n",
    "ax0 = fig.add_subplot(spec[0, 0])\n",
    "below_average = plot_data[plot_data['train'] <= 0.95 * STD_TRAIN]\n",
    "no_change = plot_data[(plot_data['train'] > 0.95 * STD_TRAIN) & (plot_data['train'] < 1.05 * STD_TRAIN)]\n",
    "above_average = plot_data[plot_data['train'] >= 1.05 * STD_TRAIN]\n",
    "\n",
    "norm_low = mpl.colors.Normalize(below_average['train'].min(), 0.95 * STD_TRAIN)\n",
    "norm_nochange = mpl.colors.Normalize(0.95 * STD_TRAIN, 1.05 * STD_TRAIN)\n",
    "norm_high = mpl.colors.Normalize(1.05 * STD_TRAIN, above_average['train'].max())\n",
    "\n",
    "ax0.bar(below_average['label'], below_average['train'], color=cmap_low(norm_low(below_average['train'])), width=0.8, zorder=2)\n",
    "ax0.bar(no_change['label'], no_change['train'], color=cmap_nochange(norm_nochange(no_change['train'])), width=0.8, zorder=2)\n",
    "ax0.bar(above_average['label'], above_average['train'], color=cmap_high(norm_high(above_average['train'])), width=0.8, zorder=2)\n",
    "\n",
    "ax0.hlines(y=STD_TRAIN, xmin=-1, xmax=12, linewidth=2, linestyle='--', color='grey', label='All Feature', zorder=3)\n",
    "ax0.set_title('a) Training', loc='left')\n",
    "ax0.set_ylabel('MASE')\n",
    "ax0.set_ylim(0.2, 0.6)\n",
    "ax0.set_xlim(-0.5, 11.5)\n",
    "ax0.set_xticks([])\n",
    "ax0.legend(loc=7, bbox_to_anchor=(0.98, 0.85), ncol=2, borderaxespad=0, frameon=True, fontsize=8)\n",
    "\n",
    "# Plot testing data\n",
    "ax1 = fig.add_subplot(spec[1, 0])\n",
    "below_average = plot_data[plot_data['test'] <= 0.95 * STD_TEST]\n",
    "no_change = plot_data[(plot_data['test'] > 0.95 * STD_TEST) & (plot_data['test'] < 1.05 * STD_TEST)]\n",
    "above_average = plot_data[plot_data['test'] >= 1.05 * STD_TEST]\n",
    "\n",
    "norm_low = mpl.colors.Normalize(below_average['test'].min(), 0.95 * STD_TEST)\n",
    "norm_nochange = mpl.colors.Normalize(0.95 * STD_TEST, 1.05 * STD_TEST)\n",
    "norm_high = mpl.colors.Normalize(1.05 * STD_TEST, above_average['test'].max())\n",
    "\n",
    "ax1.bar(below_average['label'], below_average['test'], color=cmap_low(norm_low(below_average['test'])), width=0.8, zorder=2)\n",
    "ax1.bar(no_change['label'], no_change['test'], color=cmap_nochange(norm_nochange(no_change['test'])), width=0.8, zorder=2)\n",
    "ax1.bar(above_average['label'], above_average['test'], color=cmap_high(norm_high(above_average['test'])), width=0.8, zorder=2)\n",
    "\n",
    "ax1.hlines(y=STD_TEST, xmin=-1, xmax=12, linewidth=2, linestyle='--', color='grey', label='All Feature', zorder=3)\n",
    "ax1.set_title('b) Testing', loc='left')\n",
    "ax1.set_ylabel('MASE')\n",
    "ax1.set_ylim(0.6, 1)\n",
    "ax1.set_xlim(-0.5, 11.5)\n",
    "ax1.set_xticks(plot_data['label'])\n",
    "ax1.set_xticklabels(plot_data['label'], rotation=90)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f83720f3524ad70a07f8b9522dddf168ead5e164ced993ad70b21c480e663491"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('Hyriver': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
